{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7c6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/yongming/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "### IMPORTS\n",
    "import cv2\n",
    "\n",
    "from world import *\n",
    "from world_executor import *\n",
    "from video_util import *\n",
    "from metadata_util import *\n",
    "import lens\n",
    "import point\n",
    "\n",
    "#import tasm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8cdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define some attribute for constructing the world first\n",
    "name = 'traffic_scene' # world name\n",
    "units = 'metrics'      # world units\n",
    "video_file = './amber_videos/traffic-scene-short.mp4' #example video file\n",
    "lens_attrs = {'fov': 120, \n",
    "              'cam_origin': (0, 0, 0), \n",
    "              'skew_factor': 0}\n",
    "point_attrs = {'p_id': 'p1', \n",
    "               'cam_id': 'cam1', \n",
    "               'x': 0,\n",
    "               'y': 0, \n",
    "               'z': 0,\n",
    "               'time': None, \n",
    "               'type':'pos'}\n",
    "camera_attrs = {'ratio': 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "563c392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we define a world\n",
    "new_world = World(name=name, units=units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e58555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secondly we construct the camera\n",
    "fov, res, cam_origin, skew_factor = lens_attrs['fov'], [1280, 720], lens_attrs['cam_origin'], lens_attrs['skew_factor']\n",
    "cam_lens = lens.PinholeLens(res, cam_origin, fov, skew_factor)\n",
    "\n",
    "pt_id, cam_id, x, y, z, time, pt_type = point_attrs['p_id'], point_attrs['cam_id'], point_attrs['x'], point_attrs['y'], point_attrs['z'], point_attrs['time'], point_attrs['type']\n",
    "location = point.Point(pt_id, cam_id, x, y, z, time, pt_type)\n",
    "\n",
    "ratio = camera_attrs['ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b08e3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ingest the camera to the world\n",
    "recog_world = new_world.camera(cam_id=cam_id, \n",
    "                               location=location, \n",
    "                               ratio=ratio, \n",
    "                               video_file=video_file, \n",
    "                               metadata_identifier=name+\"_\"+cam_id, \n",
    "                               lens=cam_lens)\\\n",
    "                       .recognize(cam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc37455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worlds Table created successfully........\n",
      "New world inserted successfully........\n",
      "Camera Table created successfully........\n",
      "New camera inserted successfully.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongming/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VideoContext' object has no attribute 'tasm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a06f4b031d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Call execute on the world to save the real data to the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecog_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/research/world-db/world.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Change depending if you're on docker or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mworld_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"docker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"docker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mobilitydb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mworld_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_intersection_of_interest_or_use_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/world_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Edit logic for execution here through checks of whether VideoContext or MetadataContext is being used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvideo_executor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoContextExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mvideo_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadataContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/video_context_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/video_context_executor.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mvideo_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_world\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvideo_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/video_context_executor.py\u001b[0m in \u001b[0;36mvisit_world\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcameras\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcameras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mcamera_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mall_sqls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_sqls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/video_context_executor.py\u001b[0m in \u001b[0;36mvisit_camera\u001b[0;34m(self, camera_node)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcamera_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_or_insert_camera_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_recognition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_obj_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_recognition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mvideo_data_to_tasm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcamera_sql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/research/world-db/video_context_executor.py\u001b[0m in \u001b[0;36mvisit_obj_rec\u001b[0;34m(self, camera_node, object_rec_node)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtracking_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0madd_recognized_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmetadata_to_tasm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VideoContext' object has no attribute 'tasm'"
     ]
    }
   ],
   "source": [
    "### Call execute on the world to save the real data to the database\n",
    "recog_world.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ce833",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = traffic_world.select_intersection_of_interest_or_use_default(cam_id=cam_id)\n",
    "filtered_world = traffic_world.predicate(lambda obj:obj.object_type == \"car\").predicate(lambda obj:obj.location in volume, {\"volume\":volume})\n",
    "filtered_world = filtered_world.interval([30*300,30*1200])\n",
    " \n",
    "### to get the trajectory and the video over the entire trajectory(amber case)\n",
    "filtered_ids = filtered_world.selectkey(distinct = True).execute()\n",
    "print(\"filtered_ids are\", filtered_ids)\n",
    "print(len(filtered_ids))\n",
    "if filtered_ids:\n",
    "    ### Fetch the trajectory of these items\n",
    "    trajectory = traffic_world.predicate(lambda obj: obj.object_id in id_array, {\"id_array\":id_array}).get_trajectory(distinct=True).execute()\n",
    "    print(trajectory[0])\n",
    "    \n",
    "    ### Get the videos of these items\n",
    "    print(\"fetch traj time is:\", traj_time-start)\n",
    "    entire_video = traffic_world.predicate(lambda obj: obj.object_id in id_array, {\"id_array\":id_array}).get_video()\n",
    "    print(entire_video.execute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bite8cb19f72df446e68174e40cae298cfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
